{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nyoka import skl_to_pmml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata = datasets.load_iris()\n",
    "iris = pd.DataFrame(irisdata.data,columns=irisdata.feature_names)\n",
    "iris['Species'] = irisdata.target\n",
    "\n",
    "feature_names = iris.columns.drop('Species')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris[iris.columns.drop('Species')], \n",
    "                                                    iris['Species'], test_size=0.33, random_state=101)\n",
    "\n",
    "X_test.to_csv(\"iris_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using auto dataset\n",
    "upp_names= [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "\n",
    "cars = pd.read_table(\"auto.txt\", delim_whitespace=True, names=upp_names)\n",
    "# cars=pd.read_table('auto-mpg.data',delim_whitespace=True)\n",
    "\n",
    "feature_names=cars.columns[:-1]\n",
    "target_names=cars.columns[-1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cars[feature_names] ,cars[target_names],test_size=0.33,random_state=101)\n",
    "\n",
    "X_test.to_csv(\"auto_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bike_rental_hour.csv')\n",
    "df = df.drop(['instant','dteday'],axis=1)\n",
    "X = df.drop(['cnt'],axis=1)\n",
    "y = df['cnt']\n",
    "feature_names = [name for name in df.columns if name not in ('cnt')]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "X_test.to_csv(\"bike_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adms = pd.read_csv(\"admissions.csv\")\n",
    "feature_names = adms.columns.drop(\"admit\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(adms[predictors], adms[\"admit\"], test_size=0.33,random_state=101)\n",
    "\n",
    "X_test.to_csv(path_or_buf='adms_test_X.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = pd.read_csv(\"loans_2007.csv\", encoding='latin-1')\n",
    "\n",
    "# First set of columns to drop\n",
    "loans_2007 = loans_2007.drop(['id','member_id','funded_amnt','funded_amnt_inv','grade','sub_grade',\n",
    "                              'emp_title','issue_d'],axis=1)\n",
    "\n",
    "# Second set of columns to drop\n",
    "loans_2007 = loans_2007.drop(['zip_code','out_prncp','out_prncp_inv','total_pymnt',\n",
    "                              'total_pymnt_inv','total_rec_prncp'],axis = 1)\n",
    "\n",
    "# Third set of columns to drop\n",
    "loans_2007 = loans_2007.drop(['total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee',\n",
    "                              'last_pymnt_d','last_pymnt_amnt'],axis = 1)\n",
    "\n",
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == \"Fully Paid\") | (loans_2007['loan_status'] == \"Charged Off\")]\n",
    "\n",
    "status_replace = {\n",
    "    \"loan_status\" : {\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "loans_2007 = loans_2007.replace(status_replace)\n",
    "\n",
    "\n",
    "drop_columns = []\n",
    "cols = loans_2007.columns\n",
    "for col in cols:\n",
    "    if len(loans_2007[col].dropna().unique()) == 1:\n",
    "        drop_columns.append(col)\n",
    "loans_2007 = loans_2007.drop(drop_columns, axis = 1)\n",
    "\n",
    "\n",
    "loans = loans_2007.drop('pub_rec_bankruptcies' , axis = 1)\n",
    "loans = loans.dropna(axis=0)\n",
    "\n",
    "object_columns_df = loans.select_dtypes(include=['object'])\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \"addr_state\", \"title\"], axis=1)\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans = loans.replace(mapping_dict)\n",
    "\n",
    "\n",
    "cat_columns = [\"home_ownership\", \"verification_status\", \"emp_length\", \"purpose\", \"term\"]\n",
    "dummy_df = pd.get_dummies(loans[cat_columns])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans = loans.drop(cat_columns, axis=1)\n",
    "\n",
    "cols = loans.columns\n",
    "feature_names = cols.drop(\"loan_status\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans[feature_names], loans[\"loan_status\"], test_size=0.33,random_state=101)\n",
    "X_test.to_csv(path_or_buf='loans_test_X.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_data=pd.read_csv(\"diabetes.csv\")\n",
    "X=df_data.drop('Glucose',axis=1)\n",
    "y=df_data['Glucose']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "X_test.to_csv('test_diabetes.csv')\n",
    "\n",
    "feature_names=X.columns\n",
    "target_names='Glucose'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.load_boston()\n",
    "data_frm=pd.DataFrame(data=df.data,columns=df.feature_names)\n",
    "\n",
    "data_frm['target']=df.target\n",
    "X=data_frm.drop(['target'],axis=1)\n",
    "y=data_frm['target']\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 101)\n",
    "target_names='target'\n",
    "X_test.to_csv('test_boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tita = pd.read_csv(\"titanic_train.csv\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tff = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfff = tff.fit_transform(tita['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tff.get_feature_names()\n",
    "doc = 0\n",
    "feature_index = tfff[doc,:].nonzero()[1]\n",
    "tfidf_scores = zip(feature_index, [tfff[doc, x] for x in feature_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "    print(w, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM, SVC\n",
    "ppp = Pipeline([('model',OneClassSVM())])\n",
    "ppp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skl_to_pmml(pipeline=ppp, col_names=feature_names, pmml_f_name=\"OneClassSVM.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_preds = ppp.predict(X_test)\n",
    "adapa = pd.read_csv(\"test_boston-SCORED.csv\")\n",
    "adapa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_anomaly(val):\n",
    "    if val == False:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "adapa['anomaly_score'] = adapa['anomaly'].apply(convert_anomaly)\n",
    "\n",
    "len([(i,j) for (i,j) in zip(adapa['anomaly_score'],ppp.predict(X_test)) if i!=j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', IsolationForest(bootstrap=False, contamination=0.1, max_features=1.0,\n",
       "        max_samples='auto', n_estimators=2, n_jobs=1, random_state=101,\n",
       "        verbose=0))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "iso = Pipeline([('model', IsolationForest(n_estimators=2, random_state=101))])\n",
    "iso.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05986349,  0.01909448,  0.01909448,  0.01160753,  0.01472256,\n",
       "        0.11127388, -0.03714064, -0.03254482,  0.01472256,  0.12403357,\n",
       "        0.03553708, -0.10435421,  0.09002954, -0.04045226,  0.11127388,\n",
       "        0.05649732, -0.07855471, -0.03254482,  0.00437426, -0.01534003,\n",
       "       -0.05986349,  0.09002954, -0.03254482,  0.03142963,  0.0455294 ,\n",
       "       -0.16078272, -0.10823361,  0.11127388,  0.12403357, -0.05507325,\n",
       "        0.05723013, -0.03254482,  0.05438796, -0.02991178,  0.05723013,\n",
       "       -0.07855471,  0.05649732,  0.01984178, -0.07855471, -0.04045226,\n",
       "        0.09802523,  0.12403357,  0.12403357,  0.05723013, -0.08354759,\n",
       "       -0.05507325,  0.05438796, -0.02991178, -0.02914819, -0.16078272])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08019784119280912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = iso.named_steps['model']\n",
    "model.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "firs = model.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49479106])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firs.tree_.value[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_to_pmml(pipeline=iso, col_names=feature_names, pmml_f_name='IsolationForests.pmml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.364671030072245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "cn = (2*(math.log(99)+0.577215664901532860606512090082402431)) - (2*(99/100))\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f6ae4dfaffdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'est' is not defined"
     ]
    }
   ],
   "source": [
    "model = iso.named_steps['model']\n",
    "est1 = model.estimators_[0]\n",
    "tr = est.tree_\n",
    "tr.value[0]\n",
    "print(dir(model),end='')\n",
    "model.__getstate__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import PMMLPipeline, sklearn2pmml\n",
    "siso = PMMLPipeline([('model', IsolationForest(n_estimators=1,random_state=101))])\n",
    "siso.fit(X_train)\n",
    "\n",
    "sklearn2pmml(siso, \"sianomaly.pmml\", with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10823360518175151\n",
      "-0.10823360518175151\n"
     ]
    }
   ],
   "source": [
    "jppml = siso.named_steps['model']\n",
    "model = iso.named_steps['model']\n",
    "print(jppml.threshold_)\n",
    "print(model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10823361, -0.16078272, -0.16078272, -0.05986349, -0.0527445 ,\n",
       "        0.07395471, -0.01534003, -0.00655918,  0.07395471,  0.096134  ,\n",
       "       -0.10823361, -0.16078272,  0.01977555, -0.10823361,  0.07395471,\n",
       "        0.0383246 , -0.00655918, -0.00655918,  0.096134  , -0.01534003,\n",
       "       -0.05986349,  0.01977555, -0.00655918, -0.01534003,  0.0383246 ,\n",
       "       -0.16078272, -0.10823361,  0.07395471,  0.096134  , -0.00655918,\n",
       "       -0.0527445 , -0.00655918, -0.05986349,  0.0383246 , -0.0527445 ,\n",
       "       -0.00655918,  0.0383246 , -0.01534003, -0.00655918, -0.10823361,\n",
       "        0.0383246 ,  0.096134  ,  0.096134  , -0.0527445 , -0.01534003,\n",
       "       -0.00655918, -0.05986349,  0.0383246 , -0.00655918, -0.21787188])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siso.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adapa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-625b9b047f9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0madapa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anomaly_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anomaly'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_anomaly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'anomaly_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0miso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adapa' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_anomaly(val):\n",
    "    if val == False:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "adapa['anomaly_score'] = adapa['anomaly'].apply(convert_anomaly)\n",
    "\n",
    "len([(i,j) for (i,j) in zip(adapa['anomaly_score'],iso.predict(X_test)) if i!=j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapa['anomaly_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OutputField name=\"rawAnomalyScore\" optype=\"continuous\" dataType=\"double\" feature=\"predictedValue\"/>\n",
      "<OutputField name=\"normalizedAnomalyScore\" optype=\"continuous\" dataType=\"double\" feature=\"transformedValue\">\n",
      "    <Apply function=\"/\">\n",
      "        <FieldRef field=\"rawAnomalyScore\"/>\n",
      "        <Constant dataType=\"double\">8.364671030072245</Constant>\n",
      "    </Apply>\n",
      "</OutputField>\n",
      "<OutputField name=\"decisionFunction\" optype=\"continuous\" dataType=\"double\" feature=\"transformedValue\">\n",
      "    <Apply function=\"-\">\n",
      "        <Constant dataType=\"double\">0.5</Constant>\n",
      "        <Apply function=\"pow\">\n",
      "            <Constant dataType=\"double\">2.0</Constant>\n",
      "            <Apply function=\"*\">\n",
      "                <Constant dataType=\"double\">-1.0</Constant>\n",
      "                <FieldRef field=\"normalizedAnomalyScore\"/>\n",
      "            </Apply>\n",
      "        </Apply>\n",
      "    </Apply>\n",
      "</OutputField>\n",
      "<OutputField name=\"outlier\" optype=\"categorical\" dataType=\"boolean\" feature=\"transformedValue\">\n",
      "    <Apply function=\"lessOrEqual\">\n",
      "        <FieldRef field=\"decisionFunction\"/>\n",
      "        <Constant dataType=\"double\">-0.10823360518175151</Constant>\n",
      "    </Apply>\n",
      "</OutputField>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nyoka import PMML43Ext as pml\n",
    "\n",
    "output = []\n",
    "\n",
    "n = model.max_samples_\n",
    "\n",
    "op1 = pml.OutputField(name=\"rawAnomalyScore\", \n",
    "                optype=\"continuous\", \n",
    "                dataType=\"double\",\n",
    "                feature=\"predictedValue\",\n",
    "                isFinalResult=\"false\")\n",
    "\n",
    "\n",
    "op2 = pml.OutputField(name=\"normalizedAnomalyScore\",\n",
    "                optype=\"continuous\",\n",
    "                dataType=\"double\",\n",
    "                feature=\"transformedValue\",\n",
    "                isFinalResult=\"false\", \n",
    "                Apply=pml.Apply(function=\"/\", \n",
    "                                FieldRef=[pml.FieldRef(field=\"rawAnomalyScore\")], \n",
    "                                Constant=[pml.Constant(dataType=\"double\",\n",
    "                                                       valueOf_=(2.0*(math.log(n-1.0)+0.577215664901532860606512090082402431))-\n",
    "                                                                (2.0*((n-1.0)/n)))]))\n",
    "\n",
    "appl_inner_inner = pml.Apply(function=\"*\")\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=-1.0)\n",
    "fldref = pml.FieldRef(field=\"normalizedAnomalyScore\")\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_inner_inner.add_FieldRef(cnst)\n",
    "appl_inner_inner.add_FieldRef(fldref)\n",
    "\n",
    "appl_inner = pml.Apply(function='pow')\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=2.0)\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_inner.add_FieldRef(cnst)\n",
    "appl_inner_inner.original_tagname_='Apply'\n",
    "appl_inner.add_FieldRef(appl_inner_inner)\n",
    "\n",
    "appl_outer = pml.Apply(function=\"-\")\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=0.5)\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_outer.add_FieldRef(cnst)\n",
    "appl_inner.original_tagname_='Apply'\n",
    "appl_outer.add_FieldRef(appl_inner)\n",
    "\n",
    "\n",
    "op3 = pml.OutputField(name=\"decisionFunction\",\n",
    "                      optype=\"continuous\",\n",
    "                      dataType=\"double\",\n",
    "                      feature=\"transformedValue\",\n",
    "                      isFinalResult=\"false\", \n",
    "                      Apply=appl_outer)\n",
    "\n",
    "\n",
    "op4 = pml.OutputField(name=\"outlier\",\n",
    "                      optype=\"categorical\",\n",
    "                      dataType=\"boolean\",\n",
    "                      feature=\"transformedValue\",\n",
    "                      isFinalResult=\"true\", \n",
    "                      Apply=pml.Apply(function=\"lessOrEqual\", \n",
    "                                      FieldRef=[pml.FieldRef(field=\"decisionFunction\")],\n",
    "                                      Constant=[pml.Constant(dataType=\"double\", \n",
    "                                                             valueOf_=model.threshold_)]))\n",
    "\n",
    "output.append(op1)\n",
    "output.append(op2)\n",
    "output.append(op3)\n",
    "output.append(op4)\n",
    "\n",
    "\n",
    "for op in output:\n",
    "    op.export(sys.stdout,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Output>\n",
      "    <OutputField name=\"rawAnomalyScore\" optype=\"continuous\" dataType=\"double\" feature=\"predictedValue\"/>\n",
      "    <OutputField name=\"normalizedAnomalyScore\" optype=\"continuous\" dataType=\"double\" feature=\"transformedValue\">\n",
      "        <Apply function=\"/\">\n",
      "            <FieldRef field=\"rawAnomalyScore\"/>\n",
      "            <Constant dataType=\"double\">8.364671030072245</Constant>\n",
      "        </Apply>\n",
      "    </OutputField>\n",
      "    <OutputField name=\"decisionFunction\" optype=\"continuous\" dataType=\"double\" feature=\"transformedValue\">\n",
      "        <Apply function=\"-\">\n",
      "            <Constant dataType=\"double\">0.5</Constant>\n",
      "            <Apply function=\"pow\">\n",
      "                <Constant dataType=\"double\">2.0</Constant>\n",
      "                <Apply function=\"*\">\n",
      "                    <Constant dataType=\"double\">-1.0</Constant>\n",
      "                    <FieldRef field=\"normalizedAnomalyScore\"/>\n",
      "                </Apply>\n",
      "            </Apply>\n",
      "        </Apply>\n",
      "    </OutputField>\n",
      "    <OutputField name=\"outlier\" optype=\"categorical\" dataType=\"boolean\" feature=\"transformedValue\">\n",
      "        <Apply function=\"lessOrEqual\">\n",
      "            <FieldRef field=\"decisionFunction\"/>\n",
      "            <Constant dataType=\"double\">-0.10823360518175151</Constant>\n",
      "        </Apply>\n",
      "    </OutputField>\n",
      "</Output>\n"
     ]
    }
   ],
   "source": [
    "output_fields = list()\n",
    "n = model.max_samples_\n",
    "eulers_gamma = 0.577215664901532860606512090082402431\n",
    "\n",
    "output_fields.append(pml.OutputField(name=\"rawAnomalyScore\", \n",
    "                                     optype=\"continuous\", \n",
    "                                     dataType=\"double\",\n",
    "                                     feature=\"predictedValue\",\n",
    "                                     isFinalResult=\"false\"))\n",
    "\n",
    "output_fields.append(pml.OutputField(name=\"normalizedAnomalyScore\",\n",
    "                                     optype=\"continuous\",\n",
    "                                     dataType=\"double\",\n",
    "                                     feature=\"transformedValue\",\n",
    "                                     isFinalResult=\"false\", \n",
    "                                     Apply=pml.Apply(function=\"/\", \n",
    "                                                     FieldRef=[pml.FieldRef(field=\"rawAnomalyScore\")], \n",
    "                                                     Constant=[pml.Constant(dataType=\"double\",\n",
    "                                                                            valueOf_=(2.0*(math.log(n-1.0)+eulers_gamma))-\n",
    "                                                                                     (2.0*((n-1.0)/n)))])))\n",
    "\n",
    "appl_inner_inner = pml.Apply(function=\"*\")\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=-1.0)\n",
    "fldref = pml.FieldRef(field=\"normalizedAnomalyScore\")\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_inner_inner.add_FieldRef(cnst)\n",
    "appl_inner_inner.add_FieldRef(fldref)\n",
    "\n",
    "appl_inner = pml.Apply(function='pow')\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=2.0)\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_inner.add_FieldRef(cnst)\n",
    "appl_inner_inner.original_tagname_='Apply'\n",
    "appl_inner.add_FieldRef(appl_inner_inner)\n",
    "\n",
    "appl_outer = pml.Apply(function=\"-\")\n",
    "cnst = pml.Constant(dataType=\"double\", valueOf_=0.5)\n",
    "cnst.original_tagname_ = 'Constant'\n",
    "appl_outer.add_FieldRef(cnst)\n",
    "appl_inner.original_tagname_='Apply'\n",
    "appl_outer.add_FieldRef(appl_inner)\n",
    "\n",
    "output_fields.append(pml.OutputField(name=\"decisionFunction\",\n",
    "                                     optype=\"continuous\",\n",
    "                                     dataType=\"double\",\n",
    "                                     feature=\"transformedValue\",\n",
    "                                     isFinalResult=\"false\", \n",
    "                                     Apply=appl_outer))\n",
    "\n",
    "output_fields.append(pml.OutputField(name=\"outlier\",\n",
    "                                     optype=\"categorical\",\n",
    "                                     dataType=\"boolean\",\n",
    "                                     feature=\"transformedValue\",\n",
    "                                     isFinalResult=\"true\", \n",
    "                                     Apply=pml.Apply(function=\"lessOrEqual\", \n",
    "                                                     FieldRef=[pml.FieldRef(field=\"decisionFunction\")],\n",
    "                                                     Constant=[pml.Constant(dataType=\"double\", \n",
    "                                                                            valueOf_=model.threshold_)])))\n",
    "\n",
    "opp = pml.Output(OutputField=output_fields)\n",
    "opp.export(sys.stdout, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
